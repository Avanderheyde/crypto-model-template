{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "738f0138",
   "metadata": {},
   "source": [
    "# Fetching and Updating Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f71b489e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import the libraries that we need to use\n",
    "#https://www.cryptodatadownload.com/blog/how-to-download-coinbase-price-data.html\n",
    "#https://docs.pro.coinbase.com/#get-product-order-book\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os.path\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ca37c3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/alderik/Documents/code/crypto-model-template'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95caeda0",
   "metadata": {},
   "source": [
    "### Fetch Data from Coinbase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9226b34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_daily_data(symbol):\n",
    "    pair_split = symbol.split('/')  # symbol must be in format XXX/XXX ie. BTC/EUR\n",
    "    symbol = pair_split[0] + '-' + pair_split[1]\n",
    "    url = f'https://api.pro.coinbase.com/products/{symbol}/candles?granularity=86400'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:  # check to make sure the response from server is good\n",
    "        data = pd.DataFrame(json.loads(response.text), columns=['unix', 'low', 'high', 'open', 'close', 'volume'])\n",
    "        data['date'] = pd.to_datetime(data['unix'], unit='s')  # convert to a readable date\n",
    "        data['vol_fiat'] = data['volume'] * data['close']      # multiply the BTC volume by closing price to approximate fiat volume\n",
    "\n",
    "        # if we failed to get any data, print an error...otherwise write the file\n",
    "        if data is None:\n",
    "            print(\"Did not return any data from Coinbase for this symbol\")\n",
    "        else:\n",
    "            data.to_csv(f'{os.getcwd()}/newdata/Coinbase_{pair_split[0] + pair_split[1]}_dailydata.csv', index=False)\n",
    "    else:\n",
    "        print(\"Did not receieve OK response from Coinbase API\")\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # we set which pair we want to retrieve data for\n",
    "#     pair = \"LTC/USD\"\n",
    "#     fetch_daily_data(symbol=pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cce0589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tikkers = ['BTC', 'ETH', 'ADA', 'UNI', 'LTC','LINK','BCH','XLM','WBTC','FIL','AAVE', 'ATOM', 'EOS','XTZ', 'DAI', 'ALGO','DASH','SUSHI','SNX','MKR','GRT','COMP','MATIC','BAT','ZEC','MANA','ETC','UMA','YFI','BNT', 'ZRX','REN','ANKR','OMG','CGLD','CRV', 'LRC','KNC','BAL','SKL','REP','STORJ','CVC','BAND','OXT','NU','NMR','DNT']\n",
    "names = ['Bitcoin','Ethereum','Cardano','Uniswap','Litecoin','Chainlink','Bitcoin Cash','Stellar Lumens','Wrapped Bitcoin','Filecoin','Aave','Cosmos','EOS','Tezos','Dai','Algorand','Dash','SushiSwap','Synthetic Network Token','Maker', 'The Graph','Compound','Polygon','Basic Attention Token','Zcash','Decentraland','Ethereum Classic','UMA','yearn.finance','Bancor Network Token','Ox','Ren','Ankr','OMG Network','Celo','Curve DAO Token','Loopring','Kyber Network','Balancer','SKALE','Augur','Storj','Civic','Band Protocol','Orchid','NuCypher','Numeraire','district0x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d74814d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported  BTC/USD\n",
      "Imported  ETH/USD\n",
      "Imported  ADA/USD\n",
      "Imported  UNI/USD\n",
      "Imported  LTC/USD\n",
      "Imported  LINK/USD\n",
      "Imported  BCH/USD\n",
      "Imported  XLM/USD\n",
      "Imported  WBTC/USD\n",
      "Imported  FIL/USD\n",
      "Imported  AAVE/USD\n",
      "Imported  ATOM/USD\n",
      "Imported  EOS/USD\n",
      "Imported  XTZ/USD\n",
      "Imported  DAI/USD\n",
      "Imported  ALGO/USD\n",
      "Imported  DASH/USD\n",
      "Imported  SUSHI/USD\n",
      "Imported  SNX/USD\n",
      "Imported  MKR/USD\n",
      "Imported  GRT/USD\n",
      "Imported  COMP/USD\n",
      "Imported  MATIC/USD\n",
      "Imported  BAT/USD\n",
      "Imported  ZEC/USD\n",
      "Imported  MANA/USD\n",
      "Imported  ETC/USD\n",
      "Imported  UMA/USD\n",
      "Imported  YFI/USD\n",
      "Imported  BNT/USD\n",
      "Imported  ZRX/USD\n",
      "Imported  REN/USD\n",
      "Imported  ANKR/USD\n",
      "Imported  OMG/USD\n",
      "Imported  CGLD/USD\n",
      "Imported  CRV/USD\n",
      "Imported  LRC/USD\n",
      "Imported  KNC/USD\n",
      "Imported  BAL/USD\n",
      "Imported  SKL/USD\n",
      "Imported  REP/USD\n",
      "Imported  STORJ/USD\n",
      "Did not receieve OK response from Coinbase API\n",
      "Imported  CVC/USD\n",
      "Imported  BAND/USD\n",
      "Imported  OXT/USD\n",
      "Imported  NU/USD\n",
      "Imported  NMR/USD\n",
      "Did not receieve OK response from Coinbase API\n",
      "Imported  DNT/USD\n"
     ]
    }
   ],
   "source": [
    "#fetch data from Coinbase and saves in merge directory. Prints the succesful data pulls\n",
    "for i in tikkers:\n",
    "    pair = i+'/USD'\n",
    "    fetch_daily_data(pair)\n",
    "    print(\"Imported \", pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b169df",
   "metadata": {},
   "source": [
    "### Join recently fetched data with existing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b15a99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joining_new_pulled_data(tikkers):\n",
    "    \"\"\"\n",
    "    combines old scraped data with new scraped data\n",
    "    saves the new df to csv in /combinedata\n",
    "    \"\"\"\n",
    "    for i in tikkers:\n",
    "        pair = i+'USD'\n",
    "        orig_path =f'{os.getcwd()}/data/Coinbase_'+pair+'_dailydata.csv'\n",
    "        new_data_path =f'{os.getcwd()}/newdata/Coinbase_'+pair+'_dailydata.csv'\n",
    "        combined_path = f'{os.getcwd()}/data/Coinbase_'+pair+'_dailydata.csv'\n",
    "        if os.path.isfile(orig_path) == True:\n",
    "            orig = pd.read_csv(orig_path)\n",
    "            new_data = pd.read_csv(new_data_path)\n",
    "            orig['date'] = pd.to_datetime(orig['date'])\n",
    "            new_data['date'] = pd.to_datetime(new_data['date'])\n",
    "            #check if the new data data is sooner\n",
    "            if orig.loc[0].date < new_data.loc[0].date:\n",
    "                print('Adding new values for '+ pair)\n",
    "                new_rows = new_data[new_data['date'] > orig.loc[0].date]\n",
    "                full_data = orig.append(new_rows)\n",
    "                full_data = full_data.sort_values(by= 'date', ascending = False).reset_index()\n",
    "                full_data = full_data.drop(['index'], axis=1)\n",
    "                full_data.to_csv(combined_path)\n",
    "        elif os.path.isfile(new_data_path) == True:\n",
    "            full_data = pd.read_csv(new_data_path)\n",
    "            full_data.to_csv(combined_path)\n",
    "        else:\n",
    "            print(pair + ' has no data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49cb261b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVCUSD has no data\n",
      "DNTUSD has no data\n"
     ]
    }
   ],
   "source": [
    "joining_new_pulled_data(tikkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "476f8d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tikkers minus CVC and DNT becuase those don't have any data\n",
    "tikkers = ['BTC', 'ETH', 'ADA', 'UNI', 'LTC','LINK','BCH','XLM','WBTC','FIL','AAVE', 'ATOM', 'EOS','XTZ', 'DAI', 'ALGO','DASH','SUSHI','SNX','MKR','GRT','COMP','MATIC','BAT','ZEC','MANA','ETC','UMA','YFI','BNT', 'ZRX','REN','ANKR','OMG','CGLD','CRV', 'LRC','KNC','BAL','SKL','REP','STORJ','BAND','OXT','NU','NMR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "607dc19c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-09\n",
      "2020-08-09\n",
      "2021-03-18\n",
      "2020-09-17\n",
      "2020-08-09\n",
      "2020-08-09\n",
      "2020-08-09\n",
      "2020-08-09\n",
      "2020-10-20\n",
      "2020-12-09\n",
      "2020-12-15\n",
      "2020-08-09\n",
      "2020-08-09\n",
      "2020-08-09\n",
      "2020-08-09\n",
      "2020-08-09\n",
      "2020-08-09\n",
      "2021-03-11\n",
      "2020-12-15\n",
      "2020-08-09\n",
      "2020-12-17\n",
      "2020-08-09\n",
      "2021-03-11\n",
      "2021-04-20\n",
      "2020-12-08\n",
      "2021-04-20\n",
      "2020-08-09\n",
      "2020-09-08\n",
      "2020-09-15\n",
      "2020-12-15\n",
      "2020-08-09\n",
      "2020-10-06\n",
      "2021-03-25\n",
      "2020-08-09\n",
      "2020-09-01\n",
      "2021-03-25\n",
      "2020-09-15\n",
      "2020-08-09\n",
      "2020-10-06\n",
      "2021-03-11\n",
      "2020-08-09\n",
      "2021-03-25\n",
      "2020-08-11\n",
      "2020-08-09\n",
      "2020-12-02\n",
      "2020-08-18\n"
     ]
    }
   ],
   "source": [
    "#double checking the start date is the same\n",
    "for i in tikkers:\n",
    "    pair = i+'USD'\n",
    "    temp = pd.read_csv(f'{os.getcwd()}/data/Coinbase_'+pair+'_dailydata.csv', usecols = ['unix', 'low','high','open','close','volume', 'date','vol_fiat'])\n",
    "    print(temp.iloc[-1]['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d232eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
